{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\tield\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (5.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\tield\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyarrow) (1.21.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 21.3 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\tield\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastparquet in c:\\users\\tield\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.7.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\tield\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from fastparquet) (2021.10.1)\n",
      "Requirement already satisfied: numpy>=1.18 in c:\\users\\tield\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from fastparquet) (1.21.2)\n",
      "Requirement already satisfied: thrift>=0.11.0 in c:\\users\\tield\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from fastparquet) (0.15.0)\n",
      "Requirement already satisfied: cramjam>=2.3.0 in c:\\users\\tield\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from fastparquet) (2.4.0)\n",
      "Requirement already satisfied: pandas>=1.1.0 in c:\\users\\tield\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from fastparquet) (1.3.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\tield\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.1.0->fastparquet) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\tield\\appdata\\roaming\\python\\python39\\site-packages (from pandas>=1.1.0->fastparquet) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tield\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.7.3->pandas>=1.1.0->fastparquet) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 21.3 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\tield\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in c:\\users\\tield\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.9.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 21.3 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\tield\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2 as postgres\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect():\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = postgres.connect(\n",
    "            host=\"localhost\",\n",
    "            database=\"austin_test\",\n",
    "            user=\"postgres\",\n",
    "            password=\"root\")\n",
    "    except postgres.Error as e:\n",
    "        print(e)\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closeConnection(conn):\n",
    "    sucess = False\n",
    "    try:\n",
    "        conn.close()\n",
    "        sucess = True\n",
    "    except postgres.Error as e:\n",
    "        print(e)\n",
    "    \n",
    "    return sucess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeQuery(conn, sql):\n",
    "    record = None\n",
    "    try:\n",
    "        #print(sql)\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(sql)\n",
    "        record = cur.fetchall()\n",
    "        cur.close()\n",
    "    except postgres.Error as e:\n",
    "        print(e)\n",
    "        cur.execute(\"ROLLBACK\")\n",
    "        cur.close()\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeInsert(conn, sql):\n",
    "    sucess = False\n",
    "            \n",
    "    try:\n",
    "        #print(sql)\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(sql)\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "        sucess = True\n",
    "    except postgres.Error as e:\n",
    "        print(e)\n",
    "        cur.execute(\"ROLLBACK\")\n",
    "        cur.close()\n",
    "\n",
    "    return sucess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractTuplesLayerByBin(n, wgt):\n",
    "\n",
    "  try:\n",
    "    print('Extracting tuples of bin:', n, '...')\n",
    "    #Step 0: Loading the ontology\n",
    "    \n",
    "    conn = connect()\n",
    "\n",
    "    #file_name = './Austin/w07/Complete bins/austin-sl-tuple-n-itdl-'+str(n)+'bin-wgt'+str(wgt)+'.csv'\n",
    "    #tuples = pd.read_csv(file_name)\n",
    "    \n",
    "    file_name = 'C:/Users/tield/Documents/Place2vec Experiments/Austin/w05/austin-sl-tuple-n-itdl-'+str(n)+'bin-wgt'+str(wgt)+'-p.parquet'\n",
    "    tuples = pd.read_parquet(file_name)\n",
    "    #tuples = tuples[['center_poi', 'context_poi', 'distance-m']]\n",
    "    \n",
    "    #layers = [1, 2, 3]\n",
    "    layers = [1]\n",
    "    for l in layers:\n",
    "\n",
    "      layer_tuples = getTuplesFromLayer(conn, tuples, l)\n",
    "\n",
    "      #Se há dados\n",
    "      if(len(layer_tuples) > 0):\n",
    "        \n",
    "        #layer_tuples_file_name = './Austin/w07/Complete bins/austin-sl-tuple-n-itdl-'+str(n)+'bin-wgt'+str(wgt)+'-l'+str(l)+'.csv'          \n",
    "        #layer_tuples.to_csv(layer_tuples_file_name, index=False)\n",
    "        \n",
    "        layer_tuples_file_name = 'C:/Users/tield/Documents/Place2vec Experiments/Austin/w05/austin-sl-tuple-n-itdl-'+str(n)+'bin-wgt'+str(wgt)+'-l'+str(l)+'-p.parquet'          \n",
    "        layer_tuples.to_parquet(layer_tuples_file_name, compression='brotli',  index = False)\n",
    "\n",
    "    closeConnection(conn)               \n",
    "  except Exception as e:\n",
    "    #e\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTuplesFromLayer(conn, tuples, layer):\n",
    "\n",
    "  layer_tuples = pd.DataFrame(columns=tuples.columns.to_list())\n",
    "  for id, row in tuples.iterrows():\n",
    "\n",
    "    try:\n",
    "\n",
    "      centerPoILayer = getClassLevel(conn, row['center_poi'].replace('\\'', '\\'\\''))\n",
    "      contextPoILayer = getClassLevel(conn, row['context_poi'].replace('\\'', '\\'\\''))\n",
    "\n",
    "      \n",
    "      if (centerPoILayer[0][0] == contextPoILayer[0][0] and layer in centerPoILayer[0][0]):\n",
    "\n",
    "        layer_tuples = layer_tuples.append(pd.DataFrame(\n",
    "            [tuples.iloc[id].tolist()],\n",
    "            columns=tuples.columns.to_list()), ignore_index = True\n",
    "        )\n",
    "    except Exception as e:\n",
    "      e\n",
    "      #print(str(e))\n",
    "          \n",
    "  return layer_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractTuplesLayerByBinDisco(n, wgt):\n",
    "\n",
    "  try:\n",
    "    print('Extracting tuples of bin:', n, '...')\n",
    "  \n",
    "    conn = connect()\n",
    "\n",
    "    file_name = 'C:/Users/tield/Documents/Place2vec Experiments/Austin/w05/austin-sl-tuple-n-itdl-'+str(n)+'bin-wgt'+str(wgt)+'-p.parquet'\n",
    "    tuples = pd.read_parquet(file_name)\n",
    "    #tuples = tuples[['center_poi', 'context_poi', 'distance-m']]\n",
    "    \n",
    "    layers = [1, 2, 3]\n",
    "    #layers = [1]\n",
    "    for l in layers:\n",
    "      name = 'C:/Users/tield/Documents/Place2vec Experiments/Austin/w05/austin-sl-tuple-n-itdl-'+str(n)+'bin-wgt'+str(wgt)+'-l'+str(l)+'-p.csv'\n",
    "      csv_file = open(name, \"w\", newline='')\n",
    "      writer = csv.writer(csv_file, delimiter=',')\n",
    "      writer.writerow([\"center_poi\",\"context_poi\",\"distance-m\"])\n",
    "\n",
    "      for id, row in tuples.iterrows():\n",
    "\n",
    "        centerPoILayer = getClassLevel(conn, row['center_poi'].replace('\\'', '\\'\\''))\n",
    "        contextPoILayer = getClassLevel(conn, row['context_poi'].replace('\\'', '\\'\\''))\n",
    "\n",
    "        \n",
    "        if (centerPoILayer[0][0] == contextPoILayer[0][0] and l == centerPoILayer[0][0]):\n",
    "          line = tuples.iloc[id].tolist()\n",
    "          print(line)\n",
    "          writer.writerow(line)\n",
    "          break\n",
    "  \n",
    "    csv_file.close()\n",
    "    closeConnection(conn)               \n",
    "  except Exception as e:\n",
    "    #e\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractTuplesLayerByBinDiscoML(n, wgt):\n",
    "\n",
    "  try:\n",
    "    print('Extracting tuples of bin:', n, '...')\n",
    "  \n",
    "    conn = connect()\n",
    "\n",
    "    file_name = 'C:/Users/tield/Documents/Place2vec Experiments/Austin/w05/austin-sl-tuple-n-itdl-'+str(n)+'bin-wgt'+str(wgt)+'-p.parquet'\n",
    "    tuples = pd.read_parquet(file_name)\n",
    "    #tuples = tuples[['center_poi', 'context_poi', 'distance-m']]\n",
    "    \n",
    "    l = [1, 2, 3]\n",
    "    \n",
    "    name_l1 = 'C:/Users/tield/Documents/Place2vec Experiments/Austin/w05/austin-sl-tuple-n-itdl-'+str(n)+'bin-wgt'+str(wgt)+'-l'+str(l[0])+'-p.csv'\n",
    "    csv_file_l1 = open(name_l1, \"w\", newline='')\n",
    "    writer_l1 = csv.writer(csv_file_l1, delimiter=',')\n",
    "    writer_l1.writerow([\"center_poi\",\"context_poi\",\"distance-m\"])\n",
    "\n",
    "    name_l2 = 'C:/Users/tield/Documents/Place2vec Experiments/Austin/w05/austin-sl-tuple-n-itdl-'+str(n)+'bin-wgt'+str(wgt)+'-l'+str(l[1])+'-p.csv'\n",
    "    csv_file_l2 = open(name_l2, \"w\", newline='')\n",
    "    writer_l2 = csv.writer(csv_file_l2, delimiter=',')\n",
    "    writer_l2.writerow([\"center_poi\",\"context_poi\",\"distance-m\"])\n",
    "\n",
    "    name_l3 = 'C:/Users/tield/Documents/Place2vec Experiments/Austin/w05/austin-sl-tuple-n-itdl-'+str(n)+'bin-wgt'+str(wgt)+'-l'+str(l[2])+'-p.csv'\n",
    "    csv_file_l3 = open(name_l3, \"w\", newline='')\n",
    "    writer_l3 = csv.writer(csv_file_l3, delimiter=',')\n",
    "    writer_l3.writerow([\"center_poi\",\"context_poi\",\"distance-m\"])\n",
    "\n",
    "    for id, row in tuples.iterrows():\n",
    "\n",
    "      centerPoILayer = getClassLevel(conn, row['center_poi'].replace('\\'', '\\'\\''))\n",
    "      contextPoILayer = getClassLevel(conn, row['context_poi'].replace('\\'', '\\'\\''))\n",
    "\n",
    "      \n",
    "      if (centerPoILayer[0][0] == contextPoILayer[0][0]):\n",
    "        line = tuples.iloc[id].tolist()\n",
    "        if (centerPoILayer[0][0] == l[0]):\n",
    "          writer_l1.writerow(line)\n",
    "        elif (centerPoILayer[0][0] == l[1]):\n",
    "          writer_l2.writerow(line)\n",
    "        elif (centerPoILayer[0][0] == l[2]):\n",
    "          writer_l3.writerow(line)\n",
    "        break\n",
    "  \n",
    "    csv_file_l1.close()\n",
    "    csv_file_l2.close()\n",
    "    csv_file_l3.close()\n",
    "    closeConnection(conn)\n",
    "\n",
    "  except Exception as e:\n",
    "    #e\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassLevel(conn, className):\n",
    "    sql = 'SELECT level FROM category WHERE name = \\'' + className + '\\';'\n",
    "    result = executeQuery(conn, sql)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "print(\"Number of processors: \", mp.cpu_count())\n",
    "\n",
    "wgt = 0.5\n",
    "\n",
    "# Step 1: Init multiprocessing.Pool()\n",
    "pool = mp.Pool(int(mp.cpu_count()/4))\n",
    "\n",
    "# Step 2: `pool.apply` the `howmany_within_range()`\n",
    "bins = range(0, 1)\n",
    "\n",
    "pool.starmap(extractTuplesLayerByBinDisco, [(n, wgt) for n in bins])\n",
    "#pool.starmap(extractSentencesLayerByBin, [(n, wgt) for n in bins])\n",
    "\n",
    "# Step 3: Don't forget to close\n",
    "pool.close()\n",
    "print(\"Process finish.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "wgt = 0.5\n",
    "l = 1\n",
    "\n",
    "\n",
    "file_name = 'C:/Users/tield/Documents/Place2vec Experiments/Austin/w05/austin-sl-tuple-n-itdl-'+str(n)+'bin-wgt'+str(wgt)+'-p.parquet'\n",
    "tuples = pd.read_parquet(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Shopping', 'Doctors', 12.9]\n"
     ]
    }
   ],
   "source": [
    "name = 'C:/Users/tield/Documents/Place2vec Experiments/Austin/w05/austin-sl-tuple-n-itdl-'+str(n)+'bin-wgt'+str(wgt)+'-l'+str(l)+'-p.csv'\n",
    "csv_file = open(name, \"w\", newline='')\n",
    "writer = csv.writer(csv_file, delimiter=',')\n",
    "writer.writerow([\"center_poi\",\"context_poi\",\"distance-m\"])\n",
    "line = tuples.iloc[0].tolist()\n",
    "print(line)\n",
    "writer.writerow(line)\n",
    "csv_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tuples of bin: 0 ...\n",
      "['Shopping', 'Professional Services', 12.9]\n"
     ]
    }
   ],
   "source": [
    "extractTuplesLayerByBinDisco(0, 0.5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c960ebc558cb47a91b30b6a69e09ee33d8511507a0164b187e789d12f3a22a9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('place2vec': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
