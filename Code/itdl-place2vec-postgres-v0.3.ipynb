{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gensim==3.6.0\n",
    "#!pip install binary gensim==3.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 uninstall numpy -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T13:11:26.83219Z",
     "iopub.status.busy": "2021-08-15T13:11:26.831859Z",
     "iopub.status.idle": "2021-08-15T13:11:27.944056Z",
     "shell.execute_reply": "2021-08-15T13:11:27.943319Z",
     "shell.execute_reply.started": "2021-08-15T13:11:26.832161Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tield\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2 as postgres\n",
    "import psycopg2.extras\n",
    "import math\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect():\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = postgres.connect(\n",
    "            host=\"localhost\",\n",
    "            database=\"austin_test\",\n",
    "            user=\"postgres\",\n",
    "            password=\"root\",\n",
    "            port = 8000) #8000 - LACINA PC\n",
    "                         #5432 - LOCALHOST\n",
    "    except postgres.Error as e:\n",
    "        print(e)\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closeConnection(conn):\n",
    "    sucess = False\n",
    "    try:\n",
    "        conn.close()\n",
    "        sucess = True\n",
    "    except postgres.Error as e:\n",
    "        print(e)\n",
    "    \n",
    "    return sucess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeQuery(conn, sql):\n",
    "    record = None\n",
    "    try:\n",
    "        #print(sql)\n",
    "        cur = conn.cursor(cursor_factory = psycopg2.extras.RealDictCursor)\n",
    "        cur.execute(sql)\n",
    "        record = cur.fetchall()\n",
    "        cur.close()\n",
    "    except postgres.Error as e:\n",
    "        print(e)\n",
    "        cur.execute(\"ROLLBACK\")\n",
    "        cur.close()\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeInsert(conn, sql):\n",
    "    sucess = False\n",
    "            \n",
    "    try:\n",
    "        #print(sql)\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(sql)\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "        sucess = True\n",
    "    except postgres.Error as e:\n",
    "        print(e)\n",
    "        cur.execute(\"ROLLBACK\")\n",
    "        cur.close()\n",
    "\n",
    "    return sucess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T13:11:28.004993Z",
     "iopub.status.busy": "2021-08-15T13:11:28.004358Z",
     "iopub.status.idle": "2021-08-15T13:11:28.012586Z",
     "shell.execute_reply": "2021-08-15T13:11:28.011911Z",
     "shell.execute_reply.started": "2021-08-15T13:11:28.004948Z"
    }
   },
   "outputs": [],
   "source": [
    "#Recebe um id e retorna as categorias e checkin do lugar\n",
    "def getPOIInformation(conn, business_id,):\n",
    "    \n",
    "    sql = \"\"\"\n",
    "        SELECT checkin_count, name FROM pois_information WHERE id  = \\'\"\"\"+str(business_id)+ \"\"\"\\'\n",
    "    ;\"\"\"\n",
    "\n",
    "    result = executeQuery(conn, sql)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encontra todos os pontos do bin centrado em um POI trazendo suas informações (categorias e checkin)\n",
    "def getBinPOIsInformation(conn, business_id, bin_number):\n",
    "\n",
    "    result = None\n",
    "\n",
    "    sql = \"\"\"\n",
    "        SELECT fk_poi_id_context, name, checkin_count, distance_m \n",
    "        FROM bins_pois_information \n",
    "        WHERE fk_poi_id_center = \\'\"\"\"+str(business_id)+\"\"\"\\' AND fk_bin_number = \"\"\"+str(bin_number)+\"\"\";\"\"\"\n",
    "\n",
    "    result = executeQuery(conn, sql)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função que obtém as informações de uma view materializada referente ao OSM\n",
    "def getBinOSMInformation(conn, business_id, bin_number, materialized_view):\n",
    "    result = None\n",
    "\n",
    "    sql = \"\"\"\n",
    "        SELECT *\n",
    "        FROM \"\"\"+materialized_view+\"\"\"\n",
    "        WHERE id = \\'\"\"\"+str(business_id)+\"\"\"\\' AND number = \"\"\"+str(bin_number)+\"\"\";\"\"\"\n",
    "\n",
    "    #print (sql)\n",
    "\n",
    "    result = executeQuery(conn, sql)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função que obtém as estatísticas do BIN como contagem de POIs e soma dos Checkins\n",
    "def getBinStats(conn, business_id, binRange):\n",
    "\n",
    "    sql = \"\"\"\n",
    "    SELECT count(business_id) as quantity, sum(checkin_count) as total_checkin FROM poi WHERE business_id IN (\n",
    "        SELECT fk_poi_business_id_01 FROM has_distance WHERE distance_m >= \"\"\"+str(binRange[0])+\"\"\" AND distance_m < \"\"\"+str(binRange[1])+\"\"\"\n",
    "                                            AND fk_poi_business_id_02 = \\'\"\"\"+str(business_id)+\"\"\"\\'\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    result = executeQuery(conn, sql)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCategoryInformation(data, category):\n",
    "   \n",
    "    occurences = 0\n",
    "    checkin = 0\n",
    "\n",
    "     #Formato de data\n",
    "    #[business_id, checkin, category]\n",
    "    for item in data:\n",
    "        if(item[2] == category):\n",
    "            occurences = occurences + 1\n",
    "            checkin = checkin + item[1]\n",
    "    \n",
    "    return [checkin, occurences]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ITDL - [POI, POI] (Versões em Disco e Memória)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T13:11:21.417954Z",
     "iopub.status.busy": "2021-08-15T13:11:21.417286Z",
     "iopub.status.idle": "2021-08-15T13:11:21.439736Z",
     "shell.execute_reply": "2021-08-15T13:11:21.438718Z",
     "shell.execute_reply.started": "2021-08-15T13:11:21.41786Z"
    }
   },
   "outputs": [],
   "source": [
    "#Versão que salva dados na memória até o fim do processamento, só então salva no disco\n",
    "def calculateBin(df, bin_number, w=0.5):\n",
    "    \n",
    "    print(\"executing bin:\", bin_number, \"\\tweight:\", w)\n",
    "\n",
    "    #Criando canal de comunicação com a base de dados\n",
    "    connection = connect()  \n",
    "\n",
    "    if (connection != None):\n",
    "\n",
    "        #Dicionário do ITDL\n",
    "        scITDL = {} \n",
    "        i = 0  \n",
    "\n",
    "        # largura do bin\n",
    "\n",
    "        #centros\n",
    "        for id_01, poi in df.iterrows():\n",
    "            #print('calculating point:', id_01, 'id:', poi['business_id'])\n",
    "\n",
    "            #Obtendo informações de categorias e checkin do poi central\n",
    "            #[business_id, checkin, category]\n",
    "            poi_information = getPOIInformation(connection, poi['business_id'])\n",
    "\n",
    "            \n",
    "\n",
    "            #[business_id, checkin, category, distance_m]\n",
    "            bin_information = getBinPOIsInformation(connection, poi['business_id'], bin_number)\n",
    "            \n",
    "            #Executa o processo se há dados\n",
    "            if (len(poi_information) > 0 and len(bin_information) > 0):\n",
    "\n",
    "                columns = list(dict(bin_information[0]).keys())\n",
    "\n",
    "                bin_information = pd.DataFrame(bin_information, columns = columns)\n",
    "\n",
    "                #Calculando os dois parâmetros abaixo\n",
    "\n",
    "                #sc - check-in total of all place types in bin n\n",
    "                #sp - POI total of all place types in bin n\n",
    "\n",
    "                #sp = len(bin_information['fk_poi_id_context'].unique())\n",
    "                sp = len(bin_information['name'])  #Contando todas as categorias que aparecem no bin\n",
    "\n",
    "                #sc = bin_information.drop_duplicates(subset = 'fk_poi_id_context')['checkin_count'].sum()\n",
    "                sc = bin_information['checkin_count'].sum()  #Somando todos os checkins/por categoria no bin\n",
    "\n",
    "\n",
    "                #As adições são feitas baseadas nos rótulos\n",
    "\n",
    "                #Para evitar divisão por zero\n",
    "                if(sc != 0 and sp != 0):\n",
    "                    for center_poi in poi_information: # Para cada tki\n",
    "                        for id_02, row in bin_information.iterrows(): #Para cara tkj\n",
    "\n",
    "\n",
    "                            #cc = all checkin o tkj\n",
    "                            #cp = all occurences of tkj\n",
    "\n",
    "                            cc = bin_information[bin_information['name'] == row['name']]['checkin_count'].sum()\n",
    "                            cp = bin_information[bin_information['name'] == row['name']]['name'].count()\n",
    "\n",
    "                            #print(sc, sp, cc, cp)\n",
    "\n",
    "                            a = (1 - (cc/sc)) #Pode gerar 0\n",
    "                            u = (cp/sp)       #Pode gerar 0\n",
    "\n",
    "                            if((a > 0) and (u > 0)):\n",
    "\n",
    "                                A = -np.log2(a)\n",
    "                                U = -np.log2(u)\n",
    "\n",
    "                                aug = int(math.ceil((w*A) + ((1 - w)*U)))\n",
    "\n",
    "                                #Aumentando-o pelo fator b\n",
    "                                for b in range(aug):\n",
    "\n",
    "                                    scITDL[i] = {   'poi_id_center': poi['business_id'],\n",
    "                                                    'center_poi': center_poi['name'],\n",
    "                                                    'poi_id_context': row['fk_poi_id_context'],\n",
    "                                                    'context_poi': row['name'], \n",
    "                                                    'distance-m': row['distance_m']}\n",
    "                                    i = i + 1\n",
    "\n",
    "                #break\n",
    "\n",
    "\n",
    "        scITDL = pd.DataFrame.from_dict(scITDL, 'index')\n",
    "        print(len(scITDL))\n",
    "        name = './Austin/w05/ITDL Partial Bins/austin-sl-tuple-n-itdl-' + str(bin_number) + 'bin-wgt'+str(w)+'-p.parquet'\n",
    "        scITDL.to_parquet(name, compression='brotli',  index = False)\n",
    "        closeConnection(connection)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Versão que abre arquivo no disco e salva durante o processamento\n",
    "import csv\n",
    "def calculateBin_Disco(df, bin_number, w=0.5):\n",
    "    \n",
    "    w = round(w, 1)\n",
    "    \n",
    "    print(\"executing bin:\", bin_number, \"\\tweight:\", w)\n",
    "\n",
    "    #Arquivo para salvar diretamente no disco\n",
    "    file_name = './Austin/geographic/ITDL Partial Bins/austin-sl-tuple-n-itdlcu-' + str(bin_number) + 'bin-wgt'+str(w)+'-p.csv'\n",
    "    csv_file = open(file_name, \"w\", newline='')\n",
    "    writer = csv.writer(csv_file, delimiter=',')\n",
    "    writer.writerow([\"poi_id_center\",\"center_poi\",\"poi_id_context\",\"context_poi\",\"distance-m\"])\n",
    "\n",
    "    #Criando canal de comunicação com a base de dados\n",
    "    connection = connect()  \n",
    "\n",
    "    if (connection != None):\n",
    "\n",
    "        #centros\n",
    "        for id_01, poi in df.iterrows():\n",
    "            #print('calculating point:', id_01, 'id:', poi['business_id'])\n",
    "\n",
    "            #Obtendo informações de categorias e checkin do poi central\n",
    "            #[business_id, checkin, category]\n",
    "            poi_information = getPOIInformation(connection, poi['business_id'])\n",
    "\n",
    "\n",
    "            #[business_id, checkin, category, distance_m]\n",
    "            bin_information = getBinPOIsInformation(connection, poi['business_id'], bin_number)\n",
    "            \n",
    "            #Executa o processo se há dados\n",
    "            if (len(poi_information) > 0 and len(bin_information) > 0):\n",
    "\n",
    "                columns = list(dict(bin_information[0]).keys())\n",
    "\n",
    "                bin_information = pd.DataFrame(bin_information, columns = columns)\n",
    "\n",
    "                #Calculando os dois parâmetros abaixo\n",
    "                #sc - check-in total of all place types in bin n\n",
    "                #sp - POI total of all place types in bin n\n",
    "\n",
    "                #sp = len(bin_information['fk_poi_id_context'].unique())\n",
    "                sp = len(bin_information['name'])  #Contando todas as categorias que aparecem no bin\n",
    "\n",
    "                #sc = bin_information.drop_duplicates(subset = 'fk_poi_id_context')['checkin_count'].sum()\n",
    "                sc = bin_information['checkin_count'].sum()  #Somando todos os checkins/por categoria no bin\n",
    "\n",
    "\n",
    "                #As adições são feitas baseadas nos rótulos\n",
    "\n",
    "                #Para evitar divisão por zero\n",
    "                if(sc != 0 and sp != 0):\n",
    "                    for center_poi in poi_information: # Para cada tki\n",
    "                        for id_02, row in bin_information.iterrows(): #Para cara tkj\n",
    "\n",
    "\n",
    "                            #cc = all checkin o tkj\n",
    "                            #cp = all occurences of tkj\n",
    "\n",
    "                            cc = bin_information[bin_information['name'] == row['name']]['checkin_count'].sum()\n",
    "                            cp = bin_information[bin_information['name'] == row['name']]['name'].count()\n",
    "\n",
    "                            #print(sc, sp, cc, cp)\n",
    "\n",
    "                            a = (1 - (cc/sc)) #Pode gerar 0\n",
    "                            u = (cp/sp)       #Pode gerar 0\n",
    "\n",
    "                            if((a > 0) and (u > 0)):\n",
    "\n",
    "                                A = -np.log2(a)\n",
    "                                U = -np.log2(u)\n",
    "\n",
    "                                aug = int(math.ceil((w*A) + ((1 - w)*U)))\n",
    "\n",
    "                                #Aumentando-o pelo fator b\n",
    "                                for b in range(aug):\n",
    "\n",
    "                                    line = [str(poi['business_id']), str(center_poi['name']), str(row['fk_poi_id_context']), str(row['name']), str(row['distance_m'])]\n",
    "                                    writer.writerow(line)\n",
    "\n",
    "                            \n",
    "            #break\n",
    "        \n",
    "        csv_file.close()\n",
    "        closeConnection(connection)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Versão que abre arquivo no disco e salva durante o processamento também considera a unicidade inversa com relação ao ITDL\n",
    "import csv\n",
    "def calculateBin_Disco_u(df, bin_number, w=0.5):\n",
    "    \n",
    "    print(\"executing bin:\", bin_number, \"\\tweight:\", w)\n",
    "\n",
    "    #Arquivo para salvar diretamente no disco\n",
    "    file_name = './Austin/geographic/ITDL Partial Bins/austin-sl-tuple-n-itdlu-' + str(bin_number) + 'bin-wgt'+str(w)+'-p.csv'\n",
    "    csv_file = open(file_name, \"w\", newline='')\n",
    "    writer = csv.writer(csv_file, delimiter=',')\n",
    "    writer.writerow([\"poi_id_center\",\"center_poi\",\"poi_id_context\",\"context_poi\",\"distance-m\"])\n",
    "\n",
    "    #Criando canal de comunicação com a base de dados\n",
    "    connection = connect()  \n",
    "\n",
    "    if (connection != None):\n",
    "\n",
    "        #centros\n",
    "        for id_01, poi in df.iterrows():\n",
    "            #print('calculating point:', id_01, 'id:', poi['business_id'])\n",
    "\n",
    "            #Obtendo informações de categorias e checkin do poi central\n",
    "            #[business_id, checkin, category]\n",
    "            poi_information = getPOIInformation(connection, poi['business_id'])\n",
    "\n",
    "\n",
    "            #[business_id, checkin, category, distance_m]\n",
    "            bin_information = getBinPOIsInformation(connection, poi['business_id'], bin_number)\n",
    "            \n",
    "            #Executa o processo se há dados\n",
    "            if (len(poi_information) > 0 and len(bin_information) > 0):\n",
    "\n",
    "                columns = list(dict(bin_information[0]).keys())\n",
    "\n",
    "                bin_information = pd.DataFrame(bin_information, columns = columns)\n",
    "\n",
    "                #Calculando os dois parâmetros abaixo\n",
    "                #sc - check-in total of all place types in bin n\n",
    "                #sp - POI total of all place types in bin n\n",
    "\n",
    "                #sp = len(bin_information['fk_poi_id_context'].unique())\n",
    "                sp = len(bin_information['name'])  #Contando todas as categorias que aparecem no bin\n",
    "\n",
    "                #sc = bin_information.drop_duplicates(subset = 'fk_poi_id_context')['checkin_count'].sum()\n",
    "                sc = bin_information['checkin_count'].sum()  #Somando todos os checkins/por categoria no bin\n",
    "\n",
    "\n",
    "                #As adições são feitas baseadas nos rótulos\n",
    "\n",
    "                #Para evitar divisão por zero\n",
    "                if(sc != 0 and sp != 0):\n",
    "                    for center_poi in poi_information: # Para cada tki\n",
    "                        for id_02, row in bin_information.iterrows(): #Para cara tkj\n",
    "\n",
    "\n",
    "                            #cc = all checkin o tkj\n",
    "                            #cp = all occurences of tkj\n",
    "\n",
    "                            cc = bin_information[bin_information['name'] == row['name']]['checkin_count'].sum()\n",
    "                            cp = bin_information[bin_information['name'] == row['name']]['name'].count()\n",
    "\n",
    "                            #print(sc, sp, cc, cp)\n",
    "\n",
    "                            a = (1 - (cc/sc)) #Pode gerar 0\n",
    "                            u = (1 - (cp/sp)) #Pode gerar 0\n",
    "\n",
    "                            if((a > 0) and (u > 0)):\n",
    "\n",
    "                                A = -np.log2(a)\n",
    "                                U = -np.log2(u)\n",
    "\n",
    "                                aug = int(math.ceil((w*A) + ((1 - w)*U)))\n",
    "\n",
    "                                #Aumentando-o pelo fator b\n",
    "                                for b in range(aug):\n",
    "\n",
    "                                    line = [str(poi['business_id']), str(center_poi['name']), str(row['fk_poi_id_context']), str(row['name']), str(row['distance_m'])]\n",
    "                                    writer.writerow(line)\n",
    "\n",
    "                            \n",
    "            #break\n",
    "        \n",
    "        csv_file.close()\n",
    "        closeConnection(connection)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seção de ITDL Geográfico - [POI, GEO] (Todos abaixo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def calculateBinOSMPolygon_Disco(df, bin_number, w=0.5):\n",
    "    \n",
    "    w = round(w, 1)\n",
    "    \n",
    "    print(\"executing bin:\", bin_number, \"/tweight:\", w)\n",
    "    h = 100         #Predefinido no ITDL\n",
    "\n",
    "    #Arquivo para salvar diretamente no disco\n",
    "    #name = 'C:/Users/tield/Documents/Place2vec Experiments/Austin/w05/ITDL Osm Partial Bins/austin-sl-tuple-n-itdl-' + str(n) + 'bin-wgt'+str(w)+'-bins_polygons_information-p.csv'\n",
    "    file_name = './Austin/geographic/ITDLOSM Partial Bins/austin-sl-tuple-n-itdlosm-' + str(bin_number) + 'bin-wgt'+str(w)+'-bins_polygons_information-p.csv'\n",
    "    csv_file = open(file_name, \"w\", newline='')\n",
    "    writer = csv.writer(csv_file, delimiter=',')\n",
    "    writer.writerow([\"poi_id_center\",\"center_poi\",\"osm_id_context\",\"context_osm\",\"distance-m\"])\n",
    "\n",
    "    #Criando canal de comunicação com a base de dados\n",
    "    connection = connect()  \n",
    "\n",
    "    if (connection != None):\n",
    "\n",
    "        for id_01, poi in df.iterrows():\n",
    "            #print('calculating point:', id_01, 'id:', poi['business_id'])\n",
    "\n",
    "            #[business_id, checkin, category]\n",
    "            poi_information = getPOIInformation(connection, poi['business_id'])\n",
    "\n",
    "            #bin_osm_information = []\n",
    "            #bin_osm_building_information = []\n",
    "\n",
    "            #[business_id, checkin, category, distance_m]\n",
    "            bin_osm_information = getBinOSMInformation(connection, poi['business_id'], bin_number, 'bins_polygons_information')\n",
    "            bin_osm_building_information = getBinOSMInformation(connection, poi['business_id'], bin_number, 'bins_polygons_building_information')\n",
    "\n",
    "\n",
    "            #Calculando os dois parâmetros abaixo\n",
    "            #sc - área total de todos os tipos de polygons no bin\n",
    "            #sp - total de tipos diferentes de polygons no bin\n",
    "            sp = 0\n",
    "            sc = 0\n",
    "\n",
    "            #Se o bin está preenchido com alguma informação\n",
    "            if (len(bin_osm_information) > 0):\n",
    "                tags = list(dict(bin_osm_information[0]).keys())\n",
    "                bin_osm_information = pd.DataFrame(bin_osm_information, columns = tags)\n",
    "                \n",
    "                #sp = sp + len(bin_osm_information['osm_id'].unique())\n",
    "                #Verificando quantas tipos de polygons diferentes existem\n",
    "                sp = sp + bin_osm_information.iloc[:,2:len(tags)-3][~bin_osm_information.iloc[:,2:len(tags)-3].isin(['None'])].count().sum()\n",
    "                #sc = sc + bin_osm_information['way_area_m'].sum()\n",
    "                #Verificando quantas tipos de polygons diferentes e somando suas áreas (para cada tipo de polygon)\n",
    "                sc = sc + (bin_osm_information.iloc[:,2:len(tags)-3][~bin_osm_information.iloc[:,2:len(tags)-3].isin(['None'])].count(axis=1)*bin_osm_information['way_area_m']).sum()\n",
    "\n",
    "                #Excluindo ids e bin_number\n",
    "                tags = tags[2:len(tags)-3]\n",
    "\n",
    "            #Se o bin está preenchido com alguma informação\n",
    "            if (len(bin_osm_building_information) > 0):\n",
    "                tags_buildings = list(dict(bin_osm_building_information[0]).keys())\n",
    "                bin_osm_building_information = pd.DataFrame(bin_osm_building_information, columns = tags_buildings)\n",
    "                \n",
    "                sp = sp + bin_osm_building_information.iloc[0]['building_count']\n",
    "                sc = sc + bin_osm_building_information.iloc[0]['area_total']\n",
    "\n",
    "                #Excluindo ids e bin_number\n",
    "                tags_buildings = tags_buildings[1:2]\n",
    "\n",
    "            #As adições são feitas baseadas nos rótulos\n",
    "\n",
    "            #Para evitar divisão por zero\n",
    "            if(sc != 0 and sp != 0):\n",
    "                for center_poi in poi_information: # Para cada tki\n",
    "\n",
    "                    #Calculando a co-ocorrência com polígonos que não são unicamente prédios\n",
    "                    if(len(bin_osm_information) > 0):\n",
    "                        for id_02, row in bin_osm_information.iterrows(): #Para cara polygons\n",
    "                            for tag in tags:\n",
    "                                #Percorrer cada tag\n",
    "                                \n",
    "                                value = row[tag]\n",
    "                                if (value != None): #Para tags vazias\n",
    "\n",
    "                                    #cc = all area o tag\n",
    "                                    #cp = all occurences of tag                               \n",
    "                                    cc = bin_osm_information[bin_osm_information[tag] == value]['way_area_m'].sum()\n",
    "                                    cp = bin_osm_information[bin_osm_information[tag] == value][tag].count()\n",
    "\n",
    "                                    a = (1 - (cc/sc)) #Pode gerar 0\n",
    "                                    u = (cp/sp)       #Pode gerar 0\n",
    "                                    #u = (1 - (cp/sp))       #Pode gerar 0\n",
    "\n",
    "                                    if((a > 0) and (u > 0)):\n",
    "\n",
    "                                        A = -np.log2(a)\n",
    "                                        U = -np.log2(u)\n",
    "\n",
    "                                        aug = int(math.ceil((w*A) + ((1 - w)*U)))\n",
    "                                        \n",
    "                                        #print(tag, value)\n",
    "                                        name = tag+\"_\"+value\n",
    "\n",
    "                                        #Aumentando-o pelo fator b\n",
    "                                        for b in range(aug):\n",
    "\n",
    "                                            line = [str(poi['business_id']), str(center_poi['name']), str(row['osm_id']), str(name), str(row['distance_m'])]\n",
    "                                            writer.writerow(line)\n",
    "\n",
    "                    #Calculando a co-ocorrência com polígonos que são unicamente prédios                    \n",
    "                    if (len(bin_osm_building_information) > 0):\n",
    "\n",
    "                        for id_02, row in bin_osm_building_information.iterrows(): #Para cara buildings\n",
    "\n",
    "                                \n",
    "                                #cc = all area o tag\n",
    "                                #cp = all occurences of tag\n",
    "\n",
    "                                cc = row['area_total']\n",
    "                                cp = row['building_count']\n",
    "\n",
    "                                \n",
    "                                a = (1 - (cc/sc)) #Pode gerar 0\n",
    "                                u = (cp/sp)       #Pode gerar 0\n",
    "                                #u = (1 - (cp/sp))       #Pode gerar 0\n",
    "\n",
    "                                if((a > 0) and (u > 0)):\n",
    "\n",
    "                                    A = -np.log2(a)\n",
    "                                    U = -np.log2(u)\n",
    "\n",
    "                                    aug = int(math.ceil((w*A) + ((1 - w)*U)))\n",
    "\n",
    "                                    name = 'building_yes'\n",
    "                                    distance = bin_number*h + (h/2)\n",
    "                                    building_id = '-1'\n",
    "\n",
    "                                    #Aumentando-o pelo fator b\n",
    "                                    for b in range(aug):\n",
    "\n",
    "                                        line = [str(poi['business_id']), str(center_poi['name']), building_id, str(name), str(distance)]\n",
    "                                        writer.writerow(line)\n",
    "\n",
    "                            \n",
    "            #break\n",
    "        \n",
    "        \n",
    "        csv_file.close()\n",
    "        closeConnection(connection)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def calculateBinOSMRoadsLines_Disco(df, bin_number, roads=True, w=0.5):\n",
    "    \n",
    "    if(roads):\n",
    "        materialized_view = 'bins_roads_information'\n",
    "    else:\n",
    "        materialized_view = 'bins_lines_information'\n",
    "\n",
    "    print(\"executing bin:\", bin_number, \"\\tweight:\", w)\n",
    "\n",
    "\n",
    "    #Arquivo para salvar diretamente no disco\n",
    "    #name = 'C:/Users/tield/Documents/Place2vec Experiments/Austin/w05/ITDL Osm Partial Bins/austin-sl-tuple-n-itdl-' + str(n) + 'bin-wgt'+str(w)+\"-\"+materialized_view+'-p.csv'\n",
    "    file_name = './Austin/geographic/ITDLOSM Partial Bins/austin-sl-tuple-n-itdlosm-' + str(bin_number) + 'bin-wgt'+str(w)+\"-\"+materialized_view+'-p.csv'\n",
    "    csv_file = open(file_name, \"w\", newline='')\n",
    "    writer = csv.writer(csv_file, delimiter=',')\n",
    "    writer.writerow([\"poi_id_center\",\"center_poi\",\"osm_id_context\",\"context_osm\",\"distance-m\"])\n",
    "\n",
    "    #Criando canal de comunicação com a base de dados\n",
    "    connection = connect()  \n",
    "\n",
    "    if (connection != None):\n",
    "\n",
    "        \n",
    "        #centros\n",
    "        for id_01, poi in df.iterrows():\n",
    "            #print('calculating point:', id_01, 'id:', poi['business_id'])\n",
    "\n",
    "            #[business_id, checkin, category]\n",
    "            poi_information = getPOIInformation(connection, poi['business_id'])\n",
    "\n",
    "\n",
    "            #[business_id, checkin, category, distance_m]\n",
    "            bin_osm_information = getBinOSMInformation(connection, poi['business_id'], bin_number, materialized_view)\n",
    "\n",
    "            #Se o bin está preenchido com alguma informação\n",
    "            if (len(bin_osm_information) > 0):\n",
    "                tags = list(dict(bin_osm_information[0]).keys())\n",
    "\n",
    "                bin_osm_information = pd.DataFrame(bin_osm_information, columns = tags)\n",
    "\n",
    "                \n",
    "\n",
    "                #Calculando os dois parâmetros abaixo\n",
    "                #sc - comprimento total\n",
    "                #sp - total de roads/lines no bin\n",
    "                #sp = len(bin_osm_information['osm_id'].unique())\n",
    "                #sc = bin_osm_information['length'].sum()\n",
    "\n",
    "                #sp - total de roads/lines de cada tipo no bin\n",
    "                sp = bin_osm_information.iloc[:,2:len(tags)-3][~bin_osm_information.iloc[:,2:len(tags)-3].isin(['None'])].count().sum()\n",
    "                #sc - comprimento total de cada tipo de roads/lines no bin\n",
    "                sc = (bin_osm_information.iloc[:,2:len(tags)-3][~bin_osm_information.iloc[:,2:len(tags)-3].isin(['None'])].count(axis=1)*bin_osm_information['length']).sum()\n",
    "\n",
    "                #Excluindo ids e bin_number\n",
    "                tags = tags[2:len(tags)-3]\n",
    "            \n",
    "                #As adições são feitas baseadas nos rótulos\n",
    "\n",
    "                #Para evitar divisão por zero\n",
    "                if(sc != 0 and sp != 0):\n",
    "                    for center_poi in poi_information: # Para cada tki\n",
    "                        for id_02, row in bin_osm_information.iterrows(): #Para cara tkj\n",
    "                            for tag in tags:\n",
    "                                #Percorrer cada tag\n",
    "                                \n",
    "                                value = row[tag]\n",
    "                                if (value != None): #Para tags vazias\n",
    "                                \n",
    "                                    #cc = all length o tag\n",
    "                                    #cp = all occurences of tag\n",
    "                                    cc = bin_osm_information[bin_osm_information[tag] == value]['length'].sum()\n",
    "                                    cp = bin_osm_information[bin_osm_information[tag] == value][tag].count()\n",
    "\n",
    "                                    a = (1 - (cc/sc)) #Pode gerar 0\n",
    "                                    #u = (cp/sp)       #Pode gerar 0\n",
    "                                    u = (1 - (cp/sp))       #Pode gerar 0\n",
    "\n",
    "                                    if((a > 0) and (u > 0)):\n",
    "\n",
    "                                        A = -np.log2(a)\n",
    "                                        U = -np.log2(u)\n",
    "\n",
    "                                        aug = int(math.ceil((w*A) + ((1 - w)*U)))\n",
    "\n",
    "                                        name = tag+\"_\"+value\n",
    "\n",
    "                                        #Aumentando-o pelo fator b\n",
    "                                        for b in range(aug):\n",
    "\n",
    "                                            line = [str(poi['business_id']), str(center_poi['name']), str(row['osm_id']), str(name), str(row['distance_m'])]\n",
    "                                            writer.writerow(line)\n",
    "\n",
    "                                \n",
    "            #break\n",
    "        \n",
    "        csv_file.close()\n",
    "        closeConnection(connection)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def calculateBinOSMPoints_Disco(df, bin_number):\n",
    "    \n",
    "    print(\"executing bin:\", bin_number)\n",
    "\n",
    "    #Arquivo para salvar diretamente no disco\n",
    "    #name = 'C:/Users/tield/Documents/Place2vec Experiments/Austin/w05/ITDL Osm Partial Bins/austin-sl-tuple-n-itdl-' + str(n) + '-bins_points_information-p.csv'\n",
    "    file_name = './Austin/geographic/ITDLOSM Partial Bins/austin-sl-tuple-n-itdlosm-' + str(bin_number) + 'bin-bins_points_information-p.csv'\n",
    "    csv_file = open(file_name, \"w\", newline='')\n",
    "    writer = csv.writer(csv_file, delimiter=',')\n",
    "    writer.writerow([\"poi_id_center\",\"center_poi\",\"osm_id_context\",\"context_osm\",\"distance-m\"])\n",
    "\n",
    "    #Criando canal de comunicação com a base de dados\n",
    "    connection = connect()  \n",
    "\n",
    "    if (connection != None):\n",
    "\n",
    "        for id_01, poi in df.iterrows():\n",
    "            #print('calculating point:', id_01, 'id:', poi['business_id'])\n",
    "\n",
    "            #[business_id, checkin, category]\n",
    "            poi_information = getPOIInformation(connection, poi['business_id'])\n",
    "\n",
    "\n",
    "            #[business_id, checkin, category, distance_m]\n",
    "            bin_osm_information = getBinOSMInformation(connection, poi['business_id'], bin_number, 'bins_points_information')\n",
    "\n",
    "            #Se o bin está preenchido com alguma informação\n",
    "            if (len(bin_osm_information) > 0):\n",
    "\n",
    "                tags = list(dict(bin_osm_information[0]).keys())\n",
    "                bin_osm_information = pd.DataFrame(bin_osm_information, columns = tags)\n",
    "\n",
    "               \n",
    "                #sp - total de points no bin\n",
    "                #sp = len(bin_osm_information['osm_id'].unique())\n",
    "\n",
    "                #sp - total de tipos diferentes de points no bin\n",
    "                sp = bin_osm_information.iloc[:,2:len(tags)-2][~bin_osm_information.iloc[:,2:len(tags)-2].isin(['None'])].count().sum()\n",
    "                 #Excluindo ids e bin_number\n",
    "                tags = tags[2:len(tags)-2]\n",
    "                #print(sp)\n",
    "                \n",
    "                #As adições são feitas baseadas nos rótulos\n",
    "\n",
    "                #Para evitar divisão por zero\n",
    "                if(sp != 0):\n",
    "                    for center_poi in poi_information: # Para cada tki\n",
    "                        for id_02, row in bin_osm_information.iterrows(): #Para cara tkj\n",
    "                            for tag in tags:\n",
    "                                #Percorrer cada tag\n",
    "                                \n",
    "                                value = row[tag]\n",
    "                                if (value != None): #Para tags vazias\n",
    "                                \n",
    "                                    cp = bin_osm_information[bin_osm_information[tag] == value][tag].count()\n",
    "                                    u = (cp/sp)       #Pode gerar 0\n",
    "                                    #u = (1 - (cp/sp))       #Pode gerar 0\n",
    "\n",
    "                                    if(u > 0):\n",
    "\n",
    "                                        U = -np.log2(u)\n",
    "                                        aug = int(math.ceil(U))\n",
    "\n",
    "                                        name = tag+\"_\"+value\n",
    "\n",
    "                                        #Aumentando-o pelo fator b\n",
    "                                        for b in range(aug):\n",
    "\n",
    "                                            line = [str(poi['business_id']), str(center_poi['name']), str(row['osm_id']), str(name), str(row['distance_m'])]\n",
    "                                            writer.writerow(line)\n",
    "        \n",
    "            #break\n",
    "        \n",
    "        csv_file.close()\n",
    "        closeConnection(connection)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ITDL - [POI, POI] - Utilizando Embeddings Geográficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Essa versão considera os checkins, unicidade e geografia do lugar para utilizar no fator de aumento da relação poi-poi\n",
    "import csv\n",
    "def calculateCGUBin_Disco(df, bin_number, main_parameter = 'checkin', w=0.5):\n",
    "\n",
    "    #w = round(w, 1)\n",
    "    \n",
    "    #Ajuste dos valores dos parâmetros para os três elementos\n",
    "    w_a = 0\n",
    "    w_u = 0\n",
    "    w_g = 0\n",
    "\n",
    "    \n",
    "    if (main_parameter == 'checkin'):\n",
    "        w_a = w\n",
    "        w_u = w_g = (1 - w_a)/2\n",
    "    elif (main_parameter == 'geographic'):\n",
    "        w_g = w\n",
    "        w_u = w_a = (1 - w_g)/2\n",
    "    else:\n",
    "        w_u = w\n",
    "        w_g = w_a = (1 - w_u)/2\n",
    "\n",
    "    print(\"executing bin:\", bin_number, \"\\tcheckin weight:\", w_a, '\\tproability weight:', w_u, '\\tgeographic weight:', w_g)\n",
    "\n",
    "    #Carregando vector embeddings geográficos\n",
    "    model_name = './Austin/geographic/ITDLOSM Partial Bins/austin-sl-tuple-n-itdlosm-'+str(0)+'bin-wgt0.5-points-polygons.model'\n",
    "    model = Word2Vec.load(model_name)\n",
    "\n",
    "    #Arquivo para salvar diretamente no disco\n",
    "    file_name = './Austin/geographic/ITDLG Partial Bins 2/austin-sl-tuple-n-itdlcgu-' + str(bin_number) + 'bin-'+main_parameter+'-wgt'+str(w)+'-p.csv'\n",
    "    csv_file = open(file_name, \"w\", newline='')\n",
    "    writer = csv.writer(csv_file, delimiter=',')\n",
    "    writer.writerow([\"poi_id_center\",\"center_poi\",\"poi_id_context\",\"context_poi\",\"distance-m\"])\n",
    "\n",
    "    #Criando canal de comunicação com a base de dados\n",
    "    connection = connect()  \n",
    "\n",
    "    if (connection != None):\n",
    "\n",
    "        #centros\n",
    "        for id_01, poi in df.iterrows():\n",
    "            #print('calculating point:', id_01, 'id:', poi['business_id'])\n",
    "\n",
    "            #Obtendo informações de categorias e checkin do poi central\n",
    "            #[business_id, checkin, category]\n",
    "            poi_information = getPOIInformation(connection, poi['business_id'])\n",
    "\n",
    "\n",
    "            #[business_id, checkin, category, distance_m]\n",
    "            bin_information = getBinPOIsInformation(connection, poi['business_id'], bin_number)\n",
    "            \n",
    "            #Executa o processo se há dados\n",
    "            if (len(poi_information) > 0 and len(bin_information) > 0):\n",
    "\n",
    "                columns = list(dict(bin_information[0]).keys())\n",
    "\n",
    "                bin_information = pd.DataFrame(bin_information, columns = columns)\n",
    "\n",
    "                #Calculando os dois parâmetros abaixo\n",
    "                #sc - check-in total of all place types in bin n\n",
    "                #sp - POI total of all place types in bin n\n",
    "\n",
    "                #sp = len(bin_information['fk_poi_id_context'].unique())\n",
    "                sp = len(bin_information['name'])  #Contando todas as categorias que aparecem no bin\n",
    "\n",
    "                #sc = bin_information.drop_duplicates(subset = 'fk_poi_id_context')['checkin_count'].sum()\n",
    "                sc = bin_information['checkin_count'].sum()  #Somando todos os checkins/por categoria no bin\n",
    "\n",
    "\n",
    "                #As adições são feitas baseadas nos rótulos\n",
    "\n",
    "                #Para evitar divisão por zero\n",
    "                if(sc != 0 and sp != 0):\n",
    "                    for center_poi in poi_information: # Para cada tki\n",
    "                        for id_02, row in bin_information.iterrows(): #Para cara tkj\n",
    "\n",
    "\n",
    "                            #cc = all checkin o tkj\n",
    "                            #cp = all occurences of tkj\n",
    "\n",
    "                            cc = bin_information[bin_information['name'] == row['name']]['checkin_count'].sum()\n",
    "                            cp = bin_information[bin_information['name'] == row['name']]['name'].count()\n",
    "                            \n",
    "                            try:\n",
    "                                sm = model.wv.similarity(center_poi['name'], row['name'])\n",
    "                            except:\n",
    "                                #Provável caso de falta de vocabulário\n",
    "                                sm = 0\n",
    "                            #print(sc, sp, cc, cp)\n",
    "\n",
    "                            a = (1 - (cc/sc)) \n",
    "                            u = (cp/sp)       \n",
    "                            g = (1 - sm)        #Pode gerar 0\n",
    "\n",
    "\n",
    "                            if((a > 0) and (u > 0)):\n",
    "\n",
    "                                A = -np.log2(a)\n",
    "                                U = -np.log2(u)\n",
    "                                \n",
    "                                #log2(0) = inf\n",
    "                                if (g > 0):\n",
    "                                    G = -np.log2(g)\n",
    "                                else:\n",
    "                                    G = 0\n",
    "\n",
    "                                #print('cc:', cc, ' sc:', sc, ' cc/sc:', a, ' a:', A)\n",
    "                                #print('cp:', cp, ' sp:', sp, ' cp/sp:', u, ' u:', U)\n",
    "                                #print('sm:', sm, ' g:', G)\n",
    "                                #print()\n",
    "\n",
    "                                aug = int(math.ceil((w_a*A) + (w_u*U) + (w_g*G)))\n",
    "                                #print(aug)\n",
    "\n",
    "                                #Aumentando-o pelo fator b\n",
    "                                for b in range(aug):\n",
    "\n",
    "                                    line = [str(poi['business_id']), str(center_poi['name']), str(row['fk_poi_id_context']), str(row['name']), str(row['distance_m'])]\n",
    "                                    writer.writerow(line)\n",
    "      \n",
    "            #break\n",
    "        \n",
    "        csv_file.close()\n",
    "        closeConnection(connection)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Essa versão considera apenas os vetores geográficos e a unicidade de cada lugar, descartando os checkins para aumentar a relação poi-poi\n",
    "import csv\n",
    "def calculateGUBin_Disco(df, bin_number, w=0.5):\n",
    "\n",
    "    w = round(w, 1)\n",
    "    print(\"executing bin:\", bin_number, '\\tproability weight:', (1-w), '\\tgeographic weight:', w)\n",
    "\n",
    "    #Carregando vector embeddings geográficos\n",
    "    model_name = './Austin/geographic/ITDLOSM Partial Bins/austin-sl-tuple-n-itdlosm-'+str(0)+'bin-wgt0.5-points-polygons.model'\n",
    "    model = Word2Vec.load(model_name)\n",
    "\n",
    "    #Arquivo para salvar diretamente no disco\n",
    "    file_name = './Austin/geographic/ITDLG Partial Bins 2/austin-sl-tuple-n-itdlgu-' + str(bin_number) + 'bin-wgt'+str(w)+'-p.csv'\n",
    "    csv_file = open(file_name, \"w\", newline='')\n",
    "    writer = csv.writer(csv_file, delimiter=',')\n",
    "    writer.writerow([\"poi_id_center\",\"center_poi\",\"poi_id_context\",\"context_poi\",\"distance-m\"])\n",
    "\n",
    "    #Criando canal de comunicação com a base de dados\n",
    "    connection = connect()  \n",
    "\n",
    "    if (connection != None):\n",
    "\n",
    "        #centros\n",
    "        for id_01, poi in df.iterrows():\n",
    "            #print('calculating point:', id_01, 'id:', poi['business_id'])\n",
    "\n",
    "            #Obtendo informações de categorias e checkin do poi central\n",
    "            #[business_id, checkin, category]\n",
    "            poi_information = getPOIInformation(connection, poi['business_id'])\n",
    "\n",
    "\n",
    "            #[business_id, checkin, category, distance_m]\n",
    "            bin_information = getBinPOIsInformation(connection, poi['business_id'], bin_number)\n",
    "            \n",
    "            #Executa o processo se há dados\n",
    "            if (len(poi_information) > 0 and len(bin_information) > 0):\n",
    "\n",
    "                columns = list(dict(bin_information[0]).keys())\n",
    "\n",
    "                bin_information = pd.DataFrame(bin_information, columns = columns)\n",
    "\n",
    "                #Calculando os dois parâmetros abaixo\n",
    "                #sc - check-in total of all place types in bin n\n",
    "                #sp - POI total of all place types in bin n\n",
    "\n",
    "                #sp = len(bin_information['fk_poi_id_context'].unique())\n",
    "                sp = len(bin_information['name'])  #Contando todas as categorias que aparecem no bin\n",
    "\n",
    "                #sc = bin_information.drop_duplicates(subset = 'fk_poi_id_context')['checkin_count'].sum()\n",
    "                #sc = bin_information['checkin_count'].sum()  #Somando todos os checkins/por categoria no bin\n",
    "\n",
    "\n",
    "                #As adições são feitas baseadas nos rótulos\n",
    "\n",
    "                #Para evitar divisão por zero\n",
    "                if(sp != 0):\n",
    "                    for center_poi in poi_information: # Para cada tki\n",
    "                        for id_02, row in bin_information.iterrows(): #Para cara tkj\n",
    "\n",
    "\n",
    "                            #cc = all checkin o tkj\n",
    "                            #cp = all occurences of tkj\n",
    "\n",
    "                            #cc = bin_information[bin_information['name'] == row['name']]['checkin_count'].sum()\n",
    "                            cp = bin_information[bin_information['name'] == row['name']]['name'].count()\n",
    "                            \n",
    "                            try:\n",
    "                                sm = model.wv.similarity(center_poi['name'], row['name'])\n",
    "                            except:\n",
    "                                #Provável caso de falta de vocabulário\n",
    "                                sm = 0\n",
    "                            #print(sc, sp, cc, cp)\n",
    "\n",
    "                            #a = (1 - (cc/sc)) \n",
    "                            u = (cp/sp)       \n",
    "                            g = (1 - sm)        #Pode gerar 0\n",
    "\n",
    "\n",
    "                            if((u > 0)):\n",
    "         \n",
    "                                U = -np.log2(u)\n",
    "                                \n",
    "                                #log2(0) = inf\n",
    "                                if(g > 0):\n",
    "                                    G = -np.log2(g)\n",
    "                                else:\n",
    "                                    G = 0\n",
    "\n",
    "                                #print('cc:', cc, ' sc:', sc, ' cc/sc:', a, ' a:', A)\n",
    "                                #print('cp:', cp, ' sp:', sp, ' cp/sp:', u, ' u:', U)\n",
    "                                #print('sm:', sm, ' g:', G)\n",
    "                                #print()\n",
    "\n",
    "                                aug = int(math.ceil((w*G) + ((1 - w)*U)))\n",
    "\n",
    "                                #Aumentando-o pelo fator b\n",
    "                                for b in range(aug):\n",
    "\n",
    "                                    line = [str(poi['business_id']), str(center_poi['name']), str(row['fk_poi_id_context']), str(row['name']), str(row['distance_m'])]\n",
    "                                    writer.writerow(line)\n",
    "      \n",
    "            #break\n",
    "        \n",
    "        csv_file.close()\n",
    "        closeConnection(connection)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context - POI\n",
    "Funções para encontrar o tipo do POI central a partir de elementos de contexto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match count: 13\n",
      "poi count: 91\n",
      "accuracy: 0.14285714285714285\n"
     ]
    }
   ],
   "source": [
    "def getCenterPOIByContext(df, bin_number, wgt, top = 10, context_type = 'itdl'):\n",
    "\n",
    "\n",
    "    #Criando canal de comunicação com a base de dados\n",
    "    connection = connect()  \n",
    "\n",
    "    if (connection != None):\n",
    "\n",
    "        #Selecionando um conjunto para teste\n",
    "        \n",
    "        df = df.iloc[0:99, :]\n",
    "\n",
    "        #Carregando vector embeddings geográficos\n",
    "\n",
    "        if (context_type == 'osm'):\n",
    "            model_name = 'C:/Users/tield/Documents/Doutorado UFCG/Place2vec Experiments/Austin/Geographic/ITDL-OSM Partial Bins/austin-sl-tuple-n-itdlosm-'+str(0)+'bin-wgt'+str(wgt)+'-points-polygons.model'\n",
    "            model = Word2Vec.load(model_name)\n",
    "        elif (context_type == 'geographic'):\n",
    "            model_name = 'C:/Users/tield/Documents/Doutorado UFCG/Place2vec Experiments/Austin/Geographic/ITDL-CGU Partial Bins/austin-sl-tuple-n-itdlcgu-'+str(0)+'bin-geographic-wgt'+str(wgt)+'-p.model'\n",
    "            model = Word2Vec.load(model_name)\n",
    "        elif (context_type == 'itdl'):\n",
    "            model_name = 'C:/Users/tield/Documents/Doutorado UFCG/Place2vec Experiments/Austin/Geographic/ITDL Partial Bins/austin-sl-tuple-n-itdlcu-'+str(0)+'bin-wgt'+str(wgt)+'-p.model'\n",
    "            model = Word2Vec.load(model_name)\n",
    "        else:\n",
    "            model_name = 'C:/Users/tield/Documents/Doutorado UFCG/Place2vec Experiments/Austin/Geographic/ITDL-GU Partial Bins/austin-sl-tuple-n-itdlgu-'+str(0)+'bin-wgt'+str(wgt)+'-p.model'\n",
    "            model = Word2Vec.load(model_name)\n",
    "\n",
    "        #centros\n",
    "        match_count = 0\n",
    "        poi_count = 0\n",
    "        for id, poi in df.iterrows():\n",
    "\n",
    "            \n",
    "            #Obtendo informações de um determinado POI\n",
    "            #[business_id, checkin, category]\n",
    "            poi_information = getPOIInformation(connection, poi['business_id'])\n",
    "  \n",
    "            #Obtendo POIs de contexto\n",
    "            if (context_type != 'osm'):\n",
    "\n",
    "                #Obtendo informações do bin de um POI\n",
    "                #[business_id, checkin, category, distance_m]\n",
    "                bin_information = getBinPOIsInformation(connection, poi['business_id'], bin_number)\n",
    "\n",
    "                if (len(poi_information) > 0 and len(bin_information) > 0):\n",
    "\n",
    "                    poi_count = poi_count + 1\n",
    "\n",
    "                    columns = list(dict(poi_information[0]).keys())\n",
    "                    poi_information = pd.DataFrame(poi_information, columns = columns)\n",
    "\n",
    "                    columns = list(dict(bin_information[0]).keys())\n",
    "                    bin_information = pd.DataFrame(bin_information, columns = columns)\n",
    "\n",
    "                    #Definindo intervalo de folga para considerar uma região dentro do bin\n",
    "                    center_region = bin_information[bin_information['distance_m'] <=  (((bin_number+1)*100)/2)]\n",
    "                    outer_region = bin_information[bin_information['distance_m'] > (((bin_number+1)*100)/2)]\n",
    "\n",
    "                    #poi types em determinada região\n",
    "                    center_poi_types = set(poi_information['name'].unique())\n",
    "                    context_poi_types = set(center_region['name'].unique())\n",
    "                    center_poi_types.update(context_poi_types)\n",
    "\n",
    "                    #Obtendo elementos do contexto da região\n",
    "                    context_elements = set(outer_region['name'].unique())\n",
    "                    \n",
    "                    #Predizendo possíveis pois centrais a partir do contexto\n",
    "                    predicted_pois = model.predict_output_word(context_elements, topn=top)\n",
    "\n",
    "                    #Não houve elementos para predição\n",
    "                    if (predicted_pois != None):\n",
    "\n",
    "                        predicted_center_pois = []\n",
    "                        \n",
    "                        for center_poi in predicted_pois:\n",
    "                            predicted_center_pois.append(center_poi[0])\n",
    "\n",
    "                        predicted_center_pois = set(predicted_center_pois)\n",
    "\n",
    "                        #Avaliando quantos matchs ouveram\n",
    "                        match = center_poi_types.intersection(predicted_center_pois)\n",
    "\n",
    "                        if(len(match) > 0):\n",
    "                            match_count = match_count + 1\n",
    "\n",
    "                #Obtendo elementos geográficos de contexto\n",
    "            \"\"\"else:\n",
    "\n",
    "                bin_osm_points_information = getBinOSMInformation(connection, poi['business_id'], bin_number, 'bins_points_information')\n",
    "                bin_osm_polygons_information = getBinOSMInformation(connection, poi['business_id'], bin_number, 'bins_polygons_information')\n",
    "                bin_osm_buildings_information = getBinOSMInformation(connection, poi['business_id'], bin_number, 'bins_polygons_building_information')\n",
    "                bin_osm_lines_information = getBinOSMInformation(connection, poi['business_id'], bin_number, 'bins_lines_information')\n",
    "                bin_osm_roads_information = getBinOSMInformation(connection, poi['business_id'], bin_number, 'bins_roads_information')\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "    print(\"match count:\", match_count)\n",
    "    print(\"poi count:\",poi_count)\n",
    "    print(\"accuracy:\", match_count/poi_count)\n",
    "\n",
    "getCenterPOIByContext(df, 0, 0.5, top = 15, context_type = 'itdl')\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match count: 18\n",
      "poi count: 91\n",
      "accuracy: 0.1978021978021978\n"
     ]
    }
   ],
   "source": [
    "getCenterPOIByContext(df, 0, 0.5, top = 15, context_type = 'geographic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match count: 12\n",
      "poi count: 91\n",
      "accuracy: 0.13186813186813187\n"
     ]
    }
   ],
   "source": [
    "getCenterPOIByContext(df, 0, 0.5, top = 15, context_type = 'gu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geração do ITDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T13:11:41.187138Z",
     "iopub.status.busy": "2021-08-15T13:11:41.186606Z",
     "iopub.status.idle": "2021-08-15T13:11:41.264865Z",
     "shell.execute_reply": "2021-08-15T13:11:41.264018Z",
     "shell.execute_reply.started": "2021-08-15T13:11:41.187099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22399, 7)\n",
      "(22399, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>categories</th>\n",
       "      <th>checkin_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N3_Gs3DnX4k9SgpwJxdEfw</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>30.346169</td>\n",
       "      <td>-97.711458</td>\n",
       "      <td>Shopping, Jewelry Repair, Appraisal Services, ...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tXvdYGvlEceDljN8gt2_3Q</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>30.172706</td>\n",
       "      <td>-97.799920</td>\n",
       "      <td>Barbers, Beauty &amp; Spas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nTIhpR7MhsALPwg_Hh14EA</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>30.326377</td>\n",
       "      <td>-97.704543</td>\n",
       "      <td>Hotels, Hotels &amp; Travel, Event Planning &amp; Serv...</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8XyEpVdAO0o6iVkVxkWosQ</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>30.246465</td>\n",
       "      <td>-97.778738</td>\n",
       "      <td>Home Services, Real Estate, Property Management</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NVfOn7TdnHbaGH97CVB_Qg</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>30.244902</td>\n",
       "      <td>-97.857409</td>\n",
       "      <td>Chiropractors, Health &amp; Medical</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id    city state   latitude  longitude  \\\n",
       "0  N3_Gs3DnX4k9SgpwJxdEfw  Austin    TX  30.346169 -97.711458   \n",
       "1  tXvdYGvlEceDljN8gt2_3Q  Austin    TX  30.172706 -97.799920   \n",
       "2  nTIhpR7MhsALPwg_Hh14EA  Austin    TX  30.326377 -97.704543   \n",
       "3  8XyEpVdAO0o6iVkVxkWosQ  Austin    TX  30.246465 -97.778738   \n",
       "4  NVfOn7TdnHbaGH97CVB_Qg  Austin    TX  30.244902 -97.857409   \n",
       "\n",
       "                                          categories  checkin_count  \n",
       "0  Shopping, Jewelry Repair, Appraisal Services, ...             14  \n",
       "1                             Barbers, Beauty & Spas              1  \n",
       "2  Hotels, Hotels & Travel, Event Planning & Serv...            475  \n",
       "3    Home Services, Real Estate, Property Management              0  \n",
       "4                    Chiropractors, Health & Medical             33  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quantidade de tuplas de vizinhos nos dados do yelp (center, context) considerando d = 100m\n",
    "#df = pd.read_csv('/kaggle/input/yelpcambridge/yelpcambridge-ml.csv')\n",
    "pois_file_name = 'C:/Users/tield/Documents/Doutorado UFCG/Place2vec Experiments/Cities/austin-ml-updated.csv'\n",
    "df = pd.read_csv(pois_file_name)\n",
    "print(df.shape)\n",
    "df = df.dropna()\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iteractive ITDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "43\n",
      "0.23255813953488372\n"
     ]
    }
   ],
   "source": [
    "for n in range(0, 1):\n",
    "    #res = calculateBin_Disco(df, n, 0.5)\n",
    "    #res = calculateCGUBin_Disco(df, n, main_parameter='checkin', w=0.333333)\n",
    "    getCenterPOIByContext(df, n, 0.5, context_type = 'pois')\n",
    "    #calculateBinOSMPoints_Disco(df, n)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing bin: 0 \tweight: 0.5\n"
     ]
    }
   ],
   "source": [
    "for n in range(0, 1):\n",
    "    #calculateBinOSMPolygon_Disco(df, n, 0.5)\n",
    "    #calculateBinOSMRoadsLines_Disco(df, n, roads=False, w=0.5)\n",
    "    calculateBinOSMPoints_Disco(df, n)\n",
    "    #calculateBinOSM_Disco(df, n, 'bins_points_information', 0.5)\n",
    "    #calculateBinOSM_Disco(df, n, 'bins_lines_information', 0.5)\n",
    "    #calculateBinOSM_Disco(df, n, 'bins_roads_information', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "for w in range(0, 1, 0.1):\n",
    "    calculateGeoBin_Disco(df, n, main_parameter='geographic', w=w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2291, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>centerPoI</th>\n",
       "      <th>contextPoI</th>\n",
       "      <th>distance-m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shopping</td>\n",
       "      <td>Screen Printing</td>\n",
       "      <td>13.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shopping</td>\n",
       "      <td>Screen Printing</td>\n",
       "      <td>13.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shopping</td>\n",
       "      <td>Screen Printing</td>\n",
       "      <td>13.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shopping</td>\n",
       "      <td>Screen Printing/T-Shirt Printing</td>\n",
       "      <td>13.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shopping</td>\n",
       "      <td>Screen Printing/T-Shirt Printing</td>\n",
       "      <td>13.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  centerPoI                        contextPoI  distance-m\n",
       "0  Shopping                   Screen Printing        13.1\n",
       "1  Shopping                   Screen Printing        13.1\n",
       "2  Shopping                   Screen Printing        13.1\n",
       "3  Shopping  Screen Printing/T-Shirt Printing        13.1\n",
       "4  Shopping  Screen Printing/T-Shirt Printing        13.1"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_parquet('austin-sl-tuple-n-itdl-0bin-wgt0.7-p.parquet')\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ITDL em Paralelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T21:50:03.236761Z",
     "iopub.status.busy": "2021-08-10T21:50:03.236417Z",
     "iopub.status.idle": "2021-08-10T23:51:59.673123Z",
     "shell.execute_reply": "2021-08-10T23:51:59.671871Z",
     "shell.execute_reply.started": "2021-08-10T21:50:03.236732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  8\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "print(\"Number of processors: \", mp.cpu_count())\n",
    "\n",
    "# Step 1: Init multiprocessing.Pool()\n",
    "pool = mp.Pool(int(mp.cpu_count()/2))\n",
    "\n",
    "# Step 2: `pool.apply` the `howmany_within_range()`\n",
    "bins = range(0, 4)\n",
    "#bins = [0]\n",
    "#[pool.apply(calculateBin, args=(df, n, 100, 0.3)) for n in bins]\n",
    "pool.starmap(calculateBin, [(df, n, 100, 0.7) for n in bins])\n",
    "\n",
    "# Step 3: Don't forget to close\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  16\n",
      "executing bin:executing bin:executing bin:executing bin:executing bin:   "
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "print(\"Number of processors: \", mp.cpu_count())\n",
    "\n",
    "# Step 1: Init multiprocessing.Pool()\n",
    "pool = mp.Pool(int(mp.cpu_count()-4))\n",
    "\n",
    "# Step 2: `pool.apply` the `howmany_within_range()`\n",
    "weights = np.arange(0.0, 1.1, 0.1)\n",
    "n = 8\n",
    "\n",
    "#pool.starmap(calculateBinOSMPolygon_Disco, [(df, 0,  w) for w in weights])\n",
    "#pool.starmap(calculateBinOSMRoadsLines_Disco, [(df, 0, True,  w) for w in weights])\n",
    "#pool.starmap(calculateBinOSMRoadsLines_Disco, [(df, 0, roads=True,  w) for w in weights])\n",
    "\n",
    "#pool.starmap(calculateBin_Disco, [(df, n, w) for w in weights])\n",
    "pool.starmap(calculateCGUBin_Disco, [(df, n, 'geographic', w) for w in weights])\n",
    "#pool.starmap(calculateGUBin_Disco, [(df, n,  w) for w in weights])\n",
    "\n",
    "\n",
    "# Step 3: Don't forget to close\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.arange(0.0, 1.1, 0.1)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c960ebc558cb47a91b30b6a69e09ee33d8511507a0164b187e789d12f3a22a9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
